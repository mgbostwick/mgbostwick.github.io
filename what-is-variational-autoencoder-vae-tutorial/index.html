

<!DOCTYPE html>
<meta charset="utf-8">
<title>Tutorial - What is a variational autoencoder? &#8211; Jaan Altosaar</title>
<meta name="description" content="Understanding Variational Autoencoders (VAEs) from two perspectives: deep learning and graphical models.">
<meta name="keywords" content="variational inference, autoencoder, neural networks, graphical models, inference, deep learning, machine learning">



<head>

<!-- Twitter Cards -->

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="/images/mnist.gif">

<meta name="twitter:title" content="Tutorial - What is a variational autoencoder?">
<meta name="twitter:description" content="Understanding Variational Autoencoders (VAEs) from two perspectives: deep learning and graphical models.">
<meta name="twitter:creator" content="@thejaan">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:title" content="Tutorial - What is a variational autoencoder? &#8211; Jaan Altosaar">
<meta property="og:description" content="Understanding Variational Autoencoders (VAEs) from two perspectives: deep learning and graphical models.">
<meta property="og:url" content="/what-is-variational-autoencoder-vae-tutorial/">
<meta property="og:site_name" content="Jaan Altosaar">
<meta property="og:image" content="/images/confusion-thumb.png">

<!-- Google authorship -->
<a rel="author" href="https://www.google.com/+JaanAltosaar"></a>

<!-- Google & Bing Verification -->
<meta name="google-site-verification" content="LTwvMh1s7cdUyjaHqQYsBg-I4ZPy0wm_TKUoU0IT5HU#LTwvMh1s7cdUyjaHqQYsBg-I4ZPy0wm_TKUoU0IT5HU">
<meta name="msvalidate.01" content="B3B21CDB59D1FC75DFE9B0D0CC329C8C">
</head>
<link rel="canonical" href="/what-is-variational-autoencoder-vae-tutorial/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Subscribe to the Jaan Feed">



<!-- old feed: <link href="/feed.xml" target="_blank" type="application/atom+xml" rel="alternate" title="Subscribe to the Jaan RSS Feed"> -->

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Type -->
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Crimson+Text:400,400italic,700,700italic" rel='stylesheet' type='text/css' />
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel='stylesheet' type='text/css'>
<!-- <link rel="stylesheet" href="/assets/css/entypo.css" media="all"> -->
<script async src="https://use.fontawesome.com/0a87e83674.js"></script>
<!-- In order to use Calendas Plus, you must first purchase it. Then, create a font-face package using FontSquirrel.
<link rel='stylesheet' href='/assets/cal.css' media='all' />
-->

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/i.css">

<!-- Fresh Squeezed jQuery -->
<script async src="https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js" type="text/javascript"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js" type="text/javascript"></script>
<!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> -->
<script async src="/assets/js/auto-render.min.js"></script>

<meta http-equiv="cleartype" content="on">

<script async src="/assets/js/main.js"></script>

<!-- Load Modernizr -->
<script async src="/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">

<div id="bump">
  <body class="">
    <header class="site-header darken">
      <div class="wrap">
        <hgroup>
          <h1><a href="/"><span id="jaan" class="unhilighted">Jaan</span>&nbsp;<span id="altosaar" class="hilighted">Altosaar</span></a></h1>
        </hgroup>
        <a href="#nav" class="menu"><span class='icons'>☰</span></a>
        <nav role="navigation">
          <ul>
            <!--<li>
              <a href="/" title="Jaan">Home</a>
            </li>-->
            <ul>
            
            
                
                
                <li><a href="/about" >About</a></li>
            
                
                
                <li><a href="/articles" >Articles</a></li>
            
                
                
                <li><a href="/projects" >Projects</a></li>
            
                
                
                <li><a href="/publications" >Papers</a></li>
            
                
                
                <li><a href="/talks" >Talks</a></li>
            

          </ul>
        </nav>
      </div>
    </header>


<section class="article">

  <div class="overlay overlay-lighter"></div>
  <div class="featured-image" style="background-image: url(/images/mnist.gif)"></div>


      <article class="wrap post">
        <header class="post-header">
          <hgroup>
            <h1><a href="/what-is-variational-autoencoder-vae-tutorial/">Tutorial - What is a variational autoencoder?</a></h1>
            <br>
            <!-- <p class="date">Published on <span class="date">Jul 18, 2016</span>&nbsp;|&nbsp;By <span itemprop="name" class="fn"><a href="/about" title="About Jaan Altosaar" itemprop="url">Jaan Altosaar</a></span> | <a href="/what-is-variational-autoencoder-vae-tutorial/">Permalink</a></p> -->

            <p class="intro">Understanding Variational Autoencoders (VAEs) from two perspectives: deep learning and graphical models.</p>
          </hgroup>
        </header>

        <p>Why do deep learning researchers and probabilistic machine learning folks get confused when discussing variational autoencoders? What is a variational autoencoder? Why is there unreasonable confusion surrounding this term?</p>

<p>There is a conceptual and language gap. The sciences of neural networks and probability models do not have a shared language. My goal is to bridge this idea gap and allow for more collaboration and discussion between these fields, and provide a consistent implementation (<a href="https://github.com/altosaar/vae/blob/master/vae.py">Github link</a>).</p>

<p>Variational autoencoders are cool. They let us design complex generative models of data, and fit them to large datasets. They can generate images of fictional celebrity faces and high-resolution <a href="http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/">digital artwork</a>.</p>

<figure>
    <img src="/images/variational-autoencoder-faces.jpg" style="max-width: 50%" />
    <figcaption>Fictional celebrity faces generated by a variational autoencoder (<a href="https://www.youtube.com/watch?v=XNZIN7Jh3Sg">by Alec Radford</a>). </figcaption>
</figure>

<p>These models also yield state-of-the-art machine learning results in <a href="https://arxiv.org/abs/1502.04623">image generation</a> and <a href="https://arxiv.org/abs/1509.08731">reinforcement learning</a>. Variational autoencoders (VAEs) were defined in 2013 by <a href="https://arxiv.org/abs/1312.6114">Kingma et al.</a> and <a href="https://arxiv.org/abs/1401.4082">Rezende et al.</a>.</p>

<p>How can we create a language for discussing variational autoencoders? Let’s think about them first using neural networks, then using variational inference in probability models.</p>

<h3 id="the-neural-net-perspective">The neural net perspective</h3>

<p>In neural net language, a variational autoencoder consists of an encoder, a decoder, and a loss function.</p>

<figure>
    <img src="/images/encoder-decoder.png" />
    <figcaption>The encoder compresses data into a latent space (z). The decoder reconstructs the data given the hidden representation.</figcaption>
</figure>

<p>The <em>encoder</em> is a neural network. Its input is a datapoint <script type="math/tex">x</script>, its output is a hidden representation <script type="math/tex">z</script>, and it has weights and biases <script type="math/tex">\theta</script>. To be concrete, let’s say <script type="math/tex">x</script> is a 28 by 28-pixel photo of a handwritten number. The encoder ‘encodes’ the data which is <script type="math/tex">784</script>-dimensional into a latent (hidden) representation space <script type="math/tex">z</script>, which is much less than <script type="math/tex">784</script> dimensions. This is typically referred to as a ‘bottleneck’ because the encoder must learn an efficient compression of the data into this lower-dimensional space. Let’s denote the encoder <script type="math/tex">q_\theta (z \vert x)</script>. We note that the lower-dimensional space is stochastic: the encoder outputs parameters to <script type="math/tex">q_\theta (z \vert x)</script>, which is a Gaussian probability density. We can sample from this distribution to get noisy values of the representations <script type="math/tex">z</script>.</p>

<p>The <em>decoder</em> is another neural net. Its input is the representation <script type="math/tex">z</script>, it outputs the parameters to the probability distribution of the data, and has weights and biases <script type="math/tex">\phi</script>. The decoder is denoted by <script type="math/tex">p_\phi(x\vert z)</script>. Running with the handwritten digit example, let’s say the photos are black and white and represent each pixel as <script type="math/tex">0</script> or <script type="math/tex">1</script>. The probability distribution of a single pixel can be then represented using a Bernoulli distribution. The decoder gets as input the latent representation of a digit <script type="math/tex">z</script> and outputs <script type="math/tex">784</script> Bernoulli parameters, one for each of the <script type="math/tex">784</script> pixels in the image. The decoder ‘decodes’ the real-valued numbers in <script type="math/tex">z</script> into <script type="math/tex">784</script> real-valued numbers between <script type="math/tex">0</script> and <script type="math/tex">1</script>. Information is lost because it goes from a smaller to a larger dimensionality. How much information is lost? We measure this using the reconstruction log-likelihood <script type="math/tex">\log p_\phi (x\vert z)</script> whose units are nats. This measure tells us how effectively the decoder has learned to reconstruct an input image <script type="math/tex">x</script> given its latent representation <script type="math/tex">z</script>.</p>

<p>The <em>loss function</em> of the variational autoencoder is the negative log-likelihood with a regularizer. Because there are no global representations that are shared by all datapoints, we can decompose the loss function into only terms that depend on a single datapoint <script type="math/tex">l_i</script>. The total loss is then <script type="math/tex">\sum_{i=1}^N l_i</script> for <script type="math/tex">N</script> total datapoints. The loss function <script type="math/tex">l_i</script> for datapoint <script type="math/tex">x_i</script> is:</p>

<script type="math/tex; mode=display">l_i(\theta, \phi) = - E_{z\sim q_\theta(z\vert x_i)}[\log p_\phi(x_i\vert z)] + KL(q_\theta(z\vert x_i) \vert\vert p(z))</script>

<p>The first term is the reconstruction loss, or expected negative log-likelihood of the <script type="math/tex">i</script>-th datapoint. The expectation is taken with respect to the encoder’s distribution over the representations. This term encourages the decoder to learn to reconstruct the data. If the decoder’s output does not reconstruct the data well, it will incur a large cost in this loss function.</p>

<p>The second term is a regularizer that we throw in (we’ll see how it’s derived later). This is the Kullback-Leibler divergence between the encoder’s distribution <script type="math/tex">q_\theta(z\vert x)</script> and <script type="math/tex">p(z)</script>. This divergence measures how much information is lost (in units of nats) when using <script type="math/tex">q</script> to represent <script type="math/tex">p</script>. It is one measure of how close <script type="math/tex">q</script> is to <script type="math/tex">p</script>.</p>

<p>In the variational autoencoder, <script type="math/tex">p</script> is specified as a standard Normal distribution with mean zero and variance one, or <script type="math/tex">p(z) = Normal(0,1)</script>. If the encoder outputs representations <script type="math/tex">z</script> that are different than those from a standard normal distribution, it will receive a penalty in the loss. This regularizer term means ‘keep the representations <script type="math/tex">z</script> of each digit sufficiently diverse’. If we didn’t include the regularizer, the encoder could learn to cheat and give each datapoint a representation in a different region of Euclidean space. This is bad, because then two images of the same number (say a 2 written by different people, <script type="math/tex">2_{alice}</script> and <script type="math/tex">2_{bob}</script>) could end up with very different representations <script type="math/tex">z_{alice}, z_{bob}</script>. We want the representation space of <script type="math/tex">z</script> to be meaningful, so we penalize this behavior. This has the effect of keeping similar numbers’ representations close together (e.g. so the representations of the digit two <script type="math/tex">{z_{alice}, z_{bob}, z_{ali}}</script> remain sufficiently close).</p>

<p>We train the variational autoencoder using gradient descent to optimize the loss with respect to the parameters of the encoder and decoder <script type="math/tex">\theta</script> and <script type="math/tex">\phi</script>. For stochastic gradient descent with step size <script type="math/tex">\rho</script>, the encoder parameters are updated using <script type="math/tex">\theta \leftarrow \theta - \rho \frac{\partial l}{\partial \theta}</script> and the decoder is updated similarly.</p>

<h3 id="the-probability-model-perspective">The probability model perspective</h3>

<p>Now let’s think about variational autoencoders from a probability model perspective. Please forget everything you know about deep learning and neural networks for now. Thinking about the following concepts in isolation from neural networks will clarify things. At the very end, we’ll bring back neural nets.</p>

<p>In the probability model framework, a variational autoencoder contains a specific probability model of data <script type="math/tex">x</script> and latent variables <script type="math/tex">z</script>. We can write the joint probability of the model as <script type="math/tex">p(x, z) = p(x \vert z) p(z)</script>. The generative process can be written as follows.</p>

<p>For each datapoint <script type="math/tex">i</script>:</p>

<ul>
  <li>Draw latent variables <script type="math/tex">z_i \sim p(z)</script></li>
  <li>Draw datapoint <script type="math/tex">x_i \sim p(x\vert z)</script></li>
</ul>

<p>We can represent this as a graphical model:</p>

<figure>
    <img src="/images/graphical-model-variational-autoencoder.png" width="50%" height="40px" style="max-width: 40%" />
    <figcaption>The graphical model representation of the model in the variational autoencoder. The latent variable z is a standard normal, and the data are drawn from p(x|z). The shaded node for X denotes observed data. For black and white images of handwritten digits, this data likelihood is Bernoulli distributed. </figcaption>
</figure>

<p>This is the central object we think about when discussing variational autoencoders from a probability model perspective. The latent variables are drawn from a prior <script type="math/tex">p(z)</script>. The data <script type="math/tex">x</script> have a likelihood <script type="math/tex">p(x \vert z)</script> that is conditioned on latent variables <script type="math/tex">z</script>. The model defines a joint probability distribution over data and latent variables: <script type="math/tex">p(x, z)</script>. We can decompose this into the likelihood and prior: <script type="math/tex">p(x,z) = p(x\vert z)p(z)</script>. For black and white digits, the likelihood is Bernoulli distributed.</p>

<p>Now we can think about inference in this model. The goal is to infer good values of the latent variables given observed data, or to calculate the posterior <script type="math/tex">p(z \vert x)</script>. Bayes says:</p>

<script type="math/tex; mode=display">p(z \vert x) = \frac{p(x \vert z)p(z)}{p(x)}.</script>

<p>Examine the denominator <script type="math/tex">p(x)</script>. This is called the evidence, and we can calculate it by marginalizing out the latent variables: <script type="math/tex">p(x) = \int p(x \vert z) p(z) dz</script>. Unfortunately, this integral requires exponential time to compute as it needs to be evaluated over all configurations of latent variables. We therefore need to approximate this posterior distribution.</p>

<p>Variational inference approximates the posterior with a family of distributions <script type="math/tex">q_\lambda(z \vert x)</script>. The variational parameter <script type="math/tex">\lambda</script> indexes the family of distributions. For example, if <script type="math/tex">q</script> were Gaussian, it would be the mean and variance of the latent variables for each datapoint <script type="math/tex">\lambda_{x_i} = (\mu_{x_i}, \sigma^2_{x_i}))</script>.</p>

<p>How can we know how well our variational posterior <script type="math/tex">q(z \vert x)</script> approximates the true posterior <script type="math/tex">p(z \vert x)</script>? We can use the Kullback-Leibler divergence, which measures the information lost when using <script type="math/tex">q</script> to approximate <script type="math/tex">p</script> (in units of nats):</p>

<script type="math/tex; mode=display">KL(q_\lambda(z \vert x) \vert \vert p(z \vert x)) =</script>

<script type="math/tex; mode=display">\mathbf{E}_q[\log q_\lambda(z \vert x)]- \mathbf{E}_q[\log p(x, z)] + \log p(x)</script>

<p>Our goal is to find the variational parameters <script type="math/tex">\lambda</script> that minimize this divergence. The optimal approximate posterior is thus</p>

<script type="math/tex; mode=display">q_\lambda^* (z \vert x) = {\arg\min}_\lambda KL(q_\lambda(z \vert x) \vert \vert p(z \vert x)).</script>

<p>Why is this impossible to compute directly? The pesky evidence <script type="math/tex">p(x)</script> appears in the divergence. This is intractable as discussed above. We need one more ingredient for tractable variational inference. Consider the following function:</p>

<script type="math/tex; mode=display">ELBO(\lambda) = \mathbf{E}_q[\log p(x, z)] - \mathbf{E}_q[\log q_\lambda(z \vert x)].</script>

<p>Notice that we can combine this with the Kullback-Leibler divergence and rewrite the evidence as</p>

<script type="math/tex; mode=display">\log p(x) = ELBO(\lambda) + KL(q_\lambda(z \vert x) \vert \vert p(z \vert x))</script>

<p>By Jensen’s inequality, the Kullback-Leibler divergence is always greater than or equal to zero. This means that minimizing the Kullback-Leibler divergence is equivalent to maximizing the ELBO. The abbreviation is revealed: the Evidence Lower BOund allows us to do approximate posterior inference. We are saved from having to compute and minimize the Kullback-Leibler divergence between the approximate and exact posteriors. Instead, we can maximize the ELBO which is equivalent (but computationally tractable).</p>

<p>In the variational autoencoder model, there are only local latent variables (no datapoint shares its latent <script type="math/tex">z</script> with the latent variable of another datapoint). So we can decompose the ELBO into a sum where each term depends on a single datapoint. This allows us to use stochastic gradient descent with respect to the parameters <script type="math/tex">\lambda</script>. The ELBO for a single datapoint in the variational autoencoder is:</p>

<script type="math/tex; mode=display">ELBO_i(\lambda) = E_{q_\lambda(z\vert x_i)}[\log p(x_i\vert z)] - KL(q_\lambda(z\vert x_i) \vert\vert p(z)).</script>

<p>To see that this is equivalent to our previous definition of the ELBO, expand the log joint into the prior and likelihood terms and use the product rule for the logarithm.</p>

<p>Let’s make the connection to neural net language. The final step is to parametrize the approximate posterior <script type="math/tex">q_\theta (z \vert x, \lambda)</script> with an <em>inference network</em> (or encoder) that takes as input data <script type="math/tex">x</script> and outputs parameters <script type="math/tex">\lambda</script>. We parametrize the likelihood <script type="math/tex">p(x \vert z)</script> with a <em>generative network</em> (or decoder) that takes latent variables and outputs parameters to the data distribution <script type="math/tex">p_\phi(x \vert z)</script>. The inference and generative networks have parameters <script type="math/tex">\theta</script> and <script type="math/tex">\phi</script> respectively. The parameters are typically the weights and biases of the neural nets. We optimize these to maximize the ELBO using stochastic gradient descent (there are no global latent variables, so it is kosher to minibatch our data). We can write the ELBO and include the inference and generative network parameters as:</p>

<script type="math/tex; mode=display">ELBO_i(\theta, \phi) = E_{q_\theta(z\vert x_i)}[\log p_\phi(x_i\vert z)] - KL(q_\theta(z\vert x_i) \vert\vert p(z)).</script>

<p>This evidence lower bound is the negative of the loss function for variational autoencoders we discussed from the neural net perspective; <script type="math/tex">ELBO_i(\theta, \phi) = -l_i(\theta, \phi)</script>. However, we arrived at it from principled reasoning about probability models and approximate posterior inference. We can still interpret the Kullback-Leibler divergence term as a regularizer, and the expected likelihood term as a reconstruction ‘loss’. But the probability model approach makes clear why these terms exist: to minimize the Kullback-Leibler divergence between the approximate posterior <script type="math/tex">q_\lambda(z \vert x)</script> and model posterior <script type="math/tex">p(z \vert x)</script>.</p>

<p>That’s it! We have defined a probability model, an objective function (the ELBO), and an inference algorithm (gradient ascent on the ELBO).</p>

<h3 id="experiments">Experiments</h3>

<p>Now we are ready to look at samples from the model. We have two choices to measure progress: sampling from the prior or the posterior. To give us a better idea of how to interpret the learned latent space, we can visualize what the posterior distribution of the latent variables <script type="math/tex">q_\lambda(z \vert x)</script> looks like.</p>

<p>Computationally, this means feeding an input image <script type="math/tex">x</script> through the inference network to get the parameters of the Normal distribution, then taking a sample of the latent variable <script type="math/tex">z</script>. We can plot this during training to see how the inference network learns to better approximate the posterior distribution, and place the latent variables for the different classes of digits in different parts of the latent space. Note that at the start of training, the distribution of latent variables is close to the prior (a round blob around <script type="math/tex">0</script>).</p>

<center>
<iframe src="//giphy.com/embed/26ufoVqZDjHoPrp8k?html5=true" width="480" height="413" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe>
</center>

<figure>
    <figcaption>Visualizing the learned approximate posterior during training. As training progresses the digit classes become differentiated in the two-dimensional latent space. </figcaption>
</figure>

<p>We can also visualize the prior predictive distribution. We fix the values of the latent variables to be equally spaced between <script type="math/tex">-3</script> and <script type="math/tex">3</script>. Then we can take samples from the likelihood parametrized by the generative network. These ‘hallucinated’ images show us what the model associates with each part of the latent space.</p>

<center>
<iframe src="//giphy.com/embed/26ufgj5LH3YKO1Zlu?html5=true" width="480" height="480" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe>
</center>

<figure>
    <figcaption>Visualizing the prior predictive distribution by looking at samples of the likelihood. The x and y-axes represent equally spaced latent variable values between -3 and 3 (in two dimensions). </figcaption>
</figure>

<h3 id="glossary">Glossary</h3>

<p>We need to decide on the language used for discussing variational autoencoders in a clear and concise way. Here is a glossary of terms I’ve found confusing:</p>

<ul>
  <li><strong>Variational Autoencoder (VAE)</strong>: in neural net language, a VAE consists of an encoder, a decoder, and a loss function. In probability model terms, the variational autoencoder refers to approximate inference in a latent Gaussian model where the approximate posterior and model likelihood are parametrized by neural nets (the inference and generative networks).</li>
  <li><strong>Loss function</strong>: in neural net language, we think of loss functions. Training means minimizing these loss functions. But in variational inference, we maximize the <strong>ELBO</strong> (which is not a loss function). This leads to awkwardness like calling <code>optimizer.minimize(-elbo)</code> as optimizers in neural net frameworks only support minimization.</li>
  <li><strong>Encoder</strong>: in the neural net world, the encoder is a neural network that outputs a representation <script type="math/tex">z</script> of data <script type="math/tex">x</script>. In probability model terms, the <strong>inference network</strong> parametrizes the approximate posterior of the latent variables <script type="math/tex">z</script>. The inference network outputs parameters to the distribution <script type="math/tex">q(z \vert x)</script>.</li>
  <li><strong>Decoder</strong>: in deep learning, the decoder is a neural net that learns to reconstruct the data <script type="math/tex">x</script> given a representation <script type="math/tex">z</script>. In terms of probability models, the likelihood of the data <script type="math/tex">x</script> given latent variables <script type="math/tex">z</script> is parametrized by a <strong>generative network</strong>. The generative network outputs parameters to the likelihood distribution <script type="math/tex">p(x \vert z)</script>.</li>
  <li><strong>Local latent variables</strong>: these are the <script type="math/tex">z_i</script> for each datapoint <script type="math/tex">x_i</script>. There are no global latent variables. Because there are only local latent variables, we can easily decompose the ELBO into terms <script type="math/tex">\mathcal{L}_i</script> that depend only on a single datapoint <script type="math/tex">x_i</script>. This enables stochastic gradient descent.</li>
  <li><strong>Mean-field versus amortized inference</strong>: in mean-field variational inference, we have parameters for each datapoint <script type="math/tex">\lambda_i</script> (e.g. <script type="math/tex">\lambda_i = (\mu_i, \sigma_i)</script> for Gaussian latent variables). In the variational autoencoder setting, we do <strong>amortized inference</strong> where there is a set of global parameters (in this case, the parameters <script type="math/tex">\theta</script> of the inference network). These global parameters are shared across all datapoints.</li>
  <li><strong>Inference</strong>: in neural nets, inference usually means prediction of latent representations given new, never-before-seen datapoints. In probability models, inference refers to inferring the values of latent variables given observed data.</li>
</ul>

<h3 id="sample-implementation">Sample implementation</h3>

<p>Here is a simple implementation that was used to generate the figures in this post: <a href="https://github.com/altosaar/vae/blob/master/vae.py">Github link</a></p>

<h3 id="footnote-the-reparametrization-trick">Footnote: the reparametrization trick</h3>

<p>The final thing we need to implement the variational autoencoder is how to take derivatives with respect to the parameters of a stochastic variable. If we are given <script type="math/tex">z</script> that is drawn from a distribution <script type="math/tex">q_\theta (z \vert x)</script>, and we want to take derivatives of a function of <script type="math/tex">z</script> with respect to <script type="math/tex">\theta</script>, how do we do that? The <script type="math/tex">z</script> sample is fixed, but intuitively its derivative should be nonzero.</p>

<p>For some distributions, it is possible to reparametrize samples in a clever way, such that the stochasticity is independent of the parameters. We want our samples to deterministically depend on the parameters of the distribution. For example, in a normally-distributed variable with mean <script type="math/tex">\mu</script> and standard devation <script type="math/tex">\sigma</script>, we can sample from it like this:</p>

<script type="math/tex; mode=display">z = \mu + \sigma \odot \epsilon,</script>

<p>where <script type="math/tex">\epsilon \sim Normal(0, 1)</script>. Going from <script type="math/tex">\sim</script> denoting a draw from the distribution to the equals sign <script type="math/tex">=</script> is the crucial step. We have defined a function that depends on on the parameters deterministically. We can thus take derivatives of functions involving <script type="math/tex">z</script>, <script type="math/tex">f(z)</script> with respect to the parameters of its distribution <script type="math/tex">\mu</script> and <script type="math/tex">\sigma</script>.</p>

<figure>
    <img src="/images/reparametrization.png" />
    <figcaption>The reparametrization trick allows us to push the randomness of a normally-distributed random variable z into epsilon, which is sampled from a standard normal. Diamonds indicate deterministic dependencies, circles indicate random variables. </figcaption>
</figure>

<p>In the variational autoencoder, the mean and variance are output by an inference network with parameters <script type="math/tex">\theta</script> that we optimize. The reparametrization trick lets us backpropagate (take derivatives using the chain rule) with respect to <script type="math/tex">\theta</script> through the objective (the ELBO) which is a function of samples of the latent variables <script type="math/tex">z</script>.</p>

<h3 id="references-for-ideas-and-figures">References for ideas and figures</h3>

<p>Many ideas and figures are from Shakir Mohamed’s excellent blog posts on the <a href="http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/">reparametrization trick</a> and <a href="http://blog.shakirm.com/2015/03/a-statistical-view-of-deep-learning-ii-auto-encoders-and-free-energy/">autoencoders</a>.
Durk Kingma created the great visual of the <a href="http://dpkingma.com/?page_id=277">reparametrization trick</a>. Great references for variational inference are this <a href="https://arxiv.org/abs/1601.00670">tutorial</a> and David Blei’s <a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf">course notes</a>. Dustin Tran has a helpful blog post on <a href="http://dustintran.com/blog/denoising-criterion-for-variational-auto-encoding-framework/">variational autoencoders</a>. The header’s MNIST gif is from <a href="https://github.com/RuiShu/variational-autoencoder">Rui Shu</a>.</p>

<p><em>Thanks to Rajesh Ranganath, Ben Poole, Cassandra Xia, and Ryan Sepassi for discussions and many concepts in this article.</em></p>

<p>Discussion on <a href="https://news.ycombinator.com/edit?id=12292576">Hacker News</a> and <a href="https://www.reddit.com/r/MachineLearning/comments/4xv5b5/explainer_of_variational_autoencoders_from_a/">Reddit</a>. Featured in David Duvenaud’s course syllabus on <a href="http://www.cs.toronto.edu/~duvenaud/courses/csc2541/">“Differentiable inference and generative models”</a>.</p>


      <!--<div class="sharet"><a class="share" href="https://twitter.com/intent/tweet?text=https://jaan.io/what-is-variational-autoencoder-vae-tutorial/+%40thejaan" target ="_blank" data-dnt="true"><i class="icon-twitter"></i></a>&nbsp;&nbsp;&nbsp;<a class="share" href="https://www.facebook.com/sharer/sharer.php?u=https://jaan.io/what-is-variational-autoencoder-vae-tutorial/" target="_blank"><i class="icon-facebook"></i></a>&nbsp;&nbsp;&nbsp;</div>-->

      <!--<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>-->

      

      </article>
    </section>
</div>
<script>
    var scripts = document.getElementsByTagName("script");
    for (var i = 0; i < scripts.length; i++) {
      /* TODO: keep going after an individual parse error. */
      var script = scripts[i];
      if (script.type.match(/^math\/tex/)) {
        var text = script.text === "" ? script.innerHTML : script.text;
        var options = script.type.match(/mode\s*=\s*display/) ?
                      {displayMode: true} : {};
        script.insertAdjacentHTML("beforebegin",
                                  katex.renderToString(text, options));
      }
    }
    document.body.className += " math_finished";
</script>

<div class="push"></div>
  <footert>
  <footer>
    <!--<aside class="wrap">
      <ol class="prev-posts">
        <p class="list-title"><a href="/">Recent Articles</a></p>
        
            <li>
              <span class="recent-title"><a href="/food2vec-augmented-cooking-machine-intelligence/" title="food2vec - Augmented cooking with machine intelligence">food2vec - Augmented cookin...</span>
              <span class="date">Jan 22, 2017</a></span>
            </li>
        
            <li>
              <span class="recent-title"><a href="/operator-variational-inference/" title="Operator Variational Inference">Operator Variational Inference</span>
              <span class="date">Oct 31, 2016</a></span>
            </li>
        
            <li>
              <span class="recent-title"><a href="/factorization-item-embedding/" title="Word embedding models for recommendation">Word embedding models for r...</span>
              <span class="date">Aug 05, 2016</a></span>
            </li>
        
      </ol>

      <div class="social">
        <ul>
            <li><a href="/about"><span class="foot-link">About</span></a></li>

            <li><a href="/articles"><span class="foot-link">Articles</span></a></li>

            <li><a id="mail" href="https://jaan.io/feed.xml"><span class="foot-link">Subscribe</span></a></li>



            
            <li><a id="twit" href="http://twitter.com/thejaan" target="_blank"><span class="foot-link">@thejaan</span></a></li>
            


            
        </ul>
    </div>
    </aside>-->
    <!-- <small>&copy; 2017 <a href="mailto:jaan@jaan.io"> Jaan Altosaar </a></small> -->
    <small><a href="https://twitter.com/thejaan" target="_blank"><i class="fa fa-twitter"></i></a></small>
  </footer>
</footert>

  <!-- If they're out, get some from the cellar -->
  <script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
  <script src="/assets/js/retina.min.js"></script>

  <!-- Custom JS -->
  <script async src="/assets/js/scripts.js"></script>


  
  <!-- Asynchronous Google Analytics snippet -->
  <script>
    var _gaq = _gaq || [];
    var pluginUrl =
    '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
    _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
    _gaq.push(['_setAccount', 'UA-34129661-2']);
    _gaq.push(['_trackPageview']);

  setTimeout(function() {
    window.onscroll = function() {
      window.onscroll = null; // Only track the event once
      _gaq.push(['_trackEvent', 'scroll', 'read']);
    }
  }, 5000);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
  

  </body>
</html>
